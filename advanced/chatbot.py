import os
import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.schema import HumanMessage
from langchain.memory import ConversationBufferMemory
from dotenv import load_dotenv
from transformers import pipeline

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# ëª¨ë¸ê³¼ ê°ì • ë¶„ì„ ì„¤ì •
llm = ChatOpenAI(model="gpt-4o-mini", openai_api_key=api_key)
sentiment_analyzer = pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")

# ëŒ€í™” ë§¥ë½ ìœ ì§€ë¥¼ ìœ„í•œ ë©”ëª¨ë¦¬ ì„¤ì •
memory = ConversationBufferMemory()

# Streamlit UI ì„¤ì • - í˜ì´ì§€ íƒ€ì´í‹€
st.set_page_config(page_title="ë§ˆìŒ ì‰¼í„° ìƒë‹´ ì±—ë´‡", page_icon="ğŸŒ¸")

# ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ìŠ¤íƒ€ì¼ë§ CSS ì ìš© - UIì— borderì™€ ë°°ê²½ ì¶”ê°€
st.markdown("""
    <style>
    .chat-container {
        max-width: 700px;
        margin: auto;
        padding: 10px;
        border: 1px solid #dcdcdc;
        border-radius: 15px;
        background-color: #f9f9f9;
        box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.1);
    }
    .user-message, .assistant-message {
        padding: 10px;
        border-radius: 15px;
        margin: 10px 0;
        max-width: 80%;
    }
    .user-message {
        background-color: #DCF8C6;
        text-align: left;
    }
    .assistant-message {
        background-color: #FFF3E0;
        text-align: left;
    }
    .assistant-header {
        color: #4A4A4A;
        font-weight: bold;
        margin-bottom: 5px;
    }
    .input-area {
        margin-top: 20px;
    }
    .feedback-button {
        text-align: center;
        margin-top: 20px;
    }
    </style>
""", unsafe_allow_html=True)

# UI ì‹œì‘ - ì±—ë´‡ íƒ€ì´í‹€ ë° ì„¤ëª…
st.title("ğŸŒ¸ ë§ˆìŒ ì‰¼í„° ìƒë‹´ ì±—ë´‡ ğŸŒ¸")
st.write("ì•ˆë…•í•˜ì„¸ìš”! ë”°ëœ»í•œ ë§ˆìŒìœ¼ë¡œ ê·€ ê¸°ìš¸ì—¬ ë“œë¦´ê²Œìš”. ì–¸ì œë“ ì§€ ë§ˆìŒì„ ë‚˜ëˆ ë³´ì„¸ìš”.")

# ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
st.markdown("<div class='chat-container'>", unsafe_allow_html=True)
for message in st.session_state.messages:
    role, content = message["role"], message["content"]
    style_class = "user-message" if role == "user" else "assistant-message"
    role_header = "ì‚¬ìš©ì" if role == "user" else "ìƒë‹´ ì±—ë´‡"
    st.markdown(f"<div class='{style_class}'><span class='assistant-header'>{role_header}</span><br>{content}</div>", unsafe_allow_html=True)
st.markdown("</div>", unsafe_allow_html=True)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
st.markdown("<div class='input-area'>", unsafe_allow_html=True)
if prompt := st.chat_input("ì €ì—ê²Œ ë³¸ì¸ì˜ ë§ˆìŒì„ í„¸ì–´ë†“ì•„ë³´ì„¸ìš”..."):
    # ê°ì • ë¶„ì„ ìˆ˜í–‰
    sentiment_result = sentiment_analyzer(prompt)[0]
    sentiment = sentiment_result['label']

    # ê°ì • ë¶„ì„ ê²°ê³¼ì— ë”°ë¼ í†¤ ì„¤ì •
    if sentiment in ["1 star", "2 stars"]:  # ë¶€ì •ì ì¸ ê°ì •
        tone = "ìœ„ë¡œì™€ ê³µê°ì„ ë“œë¦¬ëŠ” ì¡´ëŒ“ë§ë¡œ"
    elif sentiment in ["4 stars", "5 stars"]:  # ê¸ì •ì ì¸ ê°ì •
        tone = "ë”°ëœ»í•˜ê³  ê²©ë ¤í•˜ëŠ” ì¡´ëŒ“ë§ë¡œ"
    else:  # ì¤‘ë¦½ì ì¸ ê°ì •
        tone = "í¸ì•ˆí•˜ê³  ê³µê°ì ì¸ ì¡´ëŒ“ë§ë¡œ"

    # ì‚¬ìš©ì ì…ë ¥ ì €ì¥
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ëŒ€í™” ë§¥ë½ì„ í¬í•¨í•˜ì—¬ ëŒ€í™” í”„ë¡¬í”„íŠ¸ ìƒì„±
    conversation_history = memory.load_memory_variables({}).get("history", "")
    # ëŒ€í™”ì²´ ìŠ¤íƒ€ì¼ë¡œ ë‹µë³€ì„ ìœ ë„í•˜ëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    question_template = PromptTemplate(
        input_variables=["tone", "conversation_history", "user_input"],
        template="{tone} ë§íˆ¬ë¡œ, ë„˜ë²„ë§ ì—†ì´ ë§ˆì¹˜ ì¹œêµ¬ê°€ ì´ì•¼ê¸°í•˜ë“¯ í¸í•˜ê²Œ ì¡°ì–¸í•´ ì£¼ì„¸ìš”. ì˜ˆë¥¼ ë“¤ì–´, 'ì €ë„ ê°€ë²¼ìš´ ì‚°ì±…ì´ë‚˜ ìš´ë™ì„ í•  ë•Œ ê¸°ë¶„ì´ ë§ì´ ë‚˜ì•„ì§€ë”ë¼ê³ ìš”.' ê°™ì€ ë°©ì‹ìœ¼ë¡œ ë‹µë³€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”. ì´ì „ ëŒ€í™”: {conversation_history} ì‚¬ìš©ì ì§ˆë¬¸: {user_input}"
    )

    formatted_prompt = question_template.format(
        tone=tone, conversation_history=conversation_history, user_input=prompt
    )

    # GPT-4 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±
    answer = llm([HumanMessage(content=formatted_prompt)]).content
    with st.chat_message("assistant"):
        st.markdown(answer)
    st.session_state.messages.append({"role": "assistant", "content": answer})

    # ëŒ€í™” ë§¥ë½ ì €ì¥
    memory.save_context({"input": prompt}, {"output": answer})

st.markdown("</div>", unsafe_allow_html=True)

# ìƒë‹´ ì¢…ë£Œ ë²„íŠ¼ ë° í”¼ë“œë°± ì°½
st.markdown("<div class='feedback-button'>", unsafe_allow_html=True)
if st.button("ìƒë‹´ ì¢…ë£Œ"):
    st.subheader("ìƒë‹´ì´ ë„ì›€ì´ ë˜ì…¨ë‚˜ìš”?")
    feedback = st.radio("ìƒë‹´ ê²½í—˜ì„ í‰ê°€í•´ì£¼ì„¸ìš”:", ("ë§¤ìš° ë§Œì¡±", "ë§Œì¡±", "ë³´í†µ", "ë¶ˆë§Œì¡±", "ë§¤ìš° ë¶ˆë§Œì¡±"))
    if feedback:
        st.success("í”¼ë“œë°±ì„ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! ìƒë‹´ ì±—ë´‡ì˜ ê°œì„ ì— ë„ì›€ì´ ë©ë‹ˆë‹¤.")
st.markdown("</div>", unsafe_allow_html=True)
