import os
import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.docstore.document import Document
from langchain.prompts import PromptTemplate
from langchain.schema import HumanMessage
from dotenv import load_dotenv
from bs4 import BeautifulSoup
import requests

# .env íŒŒì¼ì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# OpenAI Chat ëª¨ë¸ ì„¤ì •
llm = ChatOpenAI(model="gpt-4o-mini", openai_api_key=api_key)

# URLì—ì„œ í…ìŠ¤íŠ¸ë¥¼ í¬ë¡¤ë§í•˜ê³  í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ
def fetch_blog_content(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, "html.parser")
    main_content = soup.find("section", class_="css-18vt64m")
    
    # main_contentê°€ ì¡´ì¬í•˜ì§€ ì•Šì„ ê²½ìš° ì²˜ë¦¬
    if main_content:
        return main_content
    else:
        return "Error: The main content could not be found. Please check the HTML structure."

# ìˆ˜ìƒì‘ ì •ë³´ ì¶”ì¶œ í•¨ìˆ˜
def extract_award_info(soup):
    awards = []
    award_sections = soup.find_all('h2')  # ìˆ˜ìƒ ì œëª©ì´ ë“¤ì–´ê°„ h2 íƒœê·¸ë¥¼ ëª¨ë‘ ì°¾ìŒ
    
    for award in award_sections:
        award_title = award.get_text()
        project_name_element = award.find_next('h2')
        project_name = project_name_element.get_text() if project_name_element else "í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"
        
        creators_element = award.find_next('p')
        creators = creators_element.get_text() if creators_element else "ì°¸ì—¬ì ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ"
        
        # ê¸°ìˆ  ìŠ¤íƒ ì •ë³´ ì¶”ì¶œ (ìš”ì•½ì— í¬í•¨)
        tech_stack = []
        tech_paragraphs = award.find_all_next('p')
        for paragraph in tech_paragraphs:
            if "ì‚¬ìš©í•œ ê¸°ìˆ  ìŠ¤íƒ" in paragraph.get_text():
                tech_stack.append(paragraph.get_text())
                break  # ì²« ë²ˆì§¸ ê¸°ìˆ  ìŠ¤íƒ ì •ë³´ë§Œ í¬í•¨
        
        # ìˆ˜ìƒ ì •ë³´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        awards.append({
            "Award Title": award_title,
            "Project Name": project_name,
            "Creators": creators,
            "Tech Stack": tech_stack[0] if tech_stack else "ê¸°ìˆ  ìŠ¤íƒ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ"  # ìš”ì•½ëœ ê¸°ìˆ  ìŠ¤íƒ ì •ë³´
        })
    
    return awards

# ë¸”ë¡œê·¸ URLì—ì„œ ìˆ˜ìƒì‘ ì •ë³´ ì¶”ì¶œ
url = "https://spartacodingclub.kr/blog/all-in-challenge_winner"
soup = fetch_blog_content(url)
award_data = extract_award_info(soup)

# Streamlit ì„¤ì • ë° ì±—ë´‡ UI
st.title("All-in Coding Challenge RAG Chatbot")
st.write("ì´ë²ˆ ì±—ë´‡ì€ 'ALL-in ì½”ë”© ê³µëª¨ì „' ìˆ˜ìƒì‘ ì •ë³´ë¥¼ ìš”ì•½í•´ì£¼ëŠ” RAG ì‹œìŠ¤í…œì…ë‹ˆë‹¤.")

# ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì €ì¥ì„ ìœ„í•œ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ëŒ€í™” ë‚´ìš©ì„ í‘œì‹œí•˜ê¸°
for message in st.session_state.messages:
    if message["role"] == "user":
        with st.chat_message("user"):
            st.markdown(message["content"])
    else:
        with st.chat_message("assistant"):
            st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ì„ ë°›ëŠ” ì¸í„°í˜ì´ìŠ¤
if prompt := st.chat_input("ì±—ë´‡ì—ê²Œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ í™”ë©´ì— í‘œì‹œí•˜ê³  ê¸°ë¡ì— ì €ì¥
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ì‚¬ìš©ì ì§ˆë¬¸ì— ë”°ë¼ ìˆ˜ìƒì‘ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìš”ì•½ ìƒì„±
    if "ALL-in ì½”ë”© ê³µëª¨ì „ ìˆ˜ìƒì‘ë“¤ì„ ìš”ì•½í•´ì¤˜" in prompt:
        # ìš”ì•½ëœ ìˆ˜ìƒì‘ ì •ë³´ ìƒì„±
        answer_content = "All-in ì½”ë”© ê³µëª¨ì „ ìˆ˜ìƒì‘ ìš”ì•½:\n\n"
        for award in award_data:
            answer_content += f"ğŸ† {award['Award Title']} - {award['Project Name']}\n"
            answer_content += f"ì œì‘ì: {award['Creators']}\n"
            answer_content += f"ê¸°ìˆ  ìŠ¤íƒ: {award['Tech Stack']}\n\n"
        
        with st.chat_message("assistant"):
            st.markdown(answer_content)
        st.session_state.messages.append({"role": "assistant", "content": answer_content})

    else:
        # RAG ì‹œìŠ¤í…œì„ ì‚¬ìš©í•´ ì‘ë‹µ ìƒì„±
        docs = vector_store.similarity_search(prompt)
        question_template = PromptTemplate(input_variables=["question"], template="{question}ì— ëŒ€í•œ ë‹µë³€ì…ë‹ˆë‹¤.")
        formatted_prompt = question_template.format(question=prompt)
        
        # ëª¨ë¸ ì‘ë‹µ ìƒì„±
        answer = llm([HumanMessage(content=formatted_prompt)])
        with st.chat_message("assistant"):
            st.markdown(answer.content)
        st.session_state.messages.append({"role": "assistant", "content": answer.content})

    # ëŒ€í™” ê¸°ë¡ì„ íŒŒì¼ë¡œ ì €ì¥
    with open("conversation_log.txt", "a") as f:
        f.write(f"ì‚¬ìš©ì: {prompt}\nì±—ë´‡: {answer_content if 'ALL-in ì½”ë”© ê³µëª¨ì „ ìˆ˜ìƒì‘ë“¤ì„ ìš”ì•½í•´ì¤˜' in prompt else answer.content}\n\n")
